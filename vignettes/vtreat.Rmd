---
title: "vtreat"
author: "John Mount, Nina Zumel"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

vtreat is a package that prepares arbitrary data frames into
clean data frames that are ready for analysis.  A clean data
frame:

- Only has numeric columns (other than the outcome).
- Has no NA/NaN in the effective variable columns.

To achieve this a number of techniques are used.  Principally:

- [Encoding category levels as indicators](http://www.win-vector.com/blog/2014/12/a-comment-on-preparing-data-for-classifiers/)
- [Impact coding](http://www.win-vector.com/blog/2012/07/modeling-trick-impact-coding-of-categorical-variables-with-many-levels/)

For more details see: [the vtreat article](http://www.win-vector.com/blog/2014/08/vtreat-designing-a-package-for-variable-treatment/)

The main pattern is the use of designTreatmentsC() or designTreatmentsN() to design a treatment plan and then use the returned structure with prepare() to apply the plan to data frames.  The main feature of vtreat is all data preparation is "y-aware" or uses the relations of effective variables to the dependent or outcome variable to encode the effective variables.

The structure returned from designTreatmentsN() or designTreatmentsC() includes informational fields.  The main fields are mostly vectors with names (all with the same names in the same order):

- vars : (character array without names) names of variables (in same order as names on the other diagnostic vectors)
- varMoves : logical TRUE if the variable varied during training, only variables that move will be in the treated frame
- PRESSRsquared : a PRESS-held out R-squared of a linear fit from each variable to the y-value.  Scores of zero and below are very bad, scores near one are very good.
- varScores : 1 - PRESSRsquared, so scores near zero are great and one and above are very bad

In additon designTreatmentsC() returns one more vector

- catPseudoRSquared : the pseudo-Rsquared (deviance ratio) of each variable in turn logisticly regressed against the categorical y target.  Similar ot the PRESSRsquared this attempts to be a hold-out statistic

In all cases we have two upward biases on the scores

- The treated variables view the training data during construction (for setting of NA values, missing values, levels, and more).  So this gives an upward bias when trying to measure treated variable utility on training data.  Until the data set is at least 1000 good rows we ignore this effect.  After 1000 rows we design variables on a pseudo-random chosen 80% of the rows and score on the complimentary 20% of the rows.
- The scoring procedure itself involves a fit (linear regression for PRESSRsquared or logistic regression for catPseudoRSquared).  So in each of these cases we would like the regression itself to be only evaluated on held-out data.  The PRESS statistic does just that (fast 1-way cross validation).   The catPseudoRSquared performs explicit 1-way cross validation for small data sets and 5-way sampling for large.


An example is:

```{r, tidy=FALSE}
library(vtreat)
dTrainC <- data.frame(x=c('a','a','a','b','b',NA),
   z=c(1,2,3,4,NA,6),y=c(FALSE,FALSE,TRUE,FALSE,TRUE,TRUE))
head(dTrainC)

dTestC <- data.frame(x=c('a','b','c',NA),z=c(10,20,30,NA))
head(dTestC)

treatmentsC <- designTreatmentsC(dTrainC,colnames(dTrainC),'y',TRUE)
print(treatmentsC)
print(treatmentsC$treatments[[1]])

dTrainCTreated <- prepare(treatmentsC,dTrainC,pruneSig=c(),scale=TRUE)
head(dTrainCTreated)

varsC <- setdiff(colnames(dTrainCTreated),'y')
# all input variables should be mean 0
sapply(dTrainCTreated[,varsC,drop=FALSE],mean)
# all slopes should be 1
sapply(varsC,function(c) { lm(paste('y',c,sep='~'),
   data=dTrainCTreated)$coefficients[[2]]})

dTestCTreated <- prepare(treatmentsC,dTestC,pruneSig=c(),scale=TRUE)
head(dTestCTreated)


# numeric example
dTrainN <- data.frame(x=c('a','a','a','a','b','b',NA),
   z=c(1,2,3,4,5,NA,7),y=c(0,0,0,1,0,1,1))
head(dTrainN)

dTestN <- data.frame(x=c('a','b','c',NA),z=c(10,20,30,NA))
head(dTestN)

treatmentsN = designTreatmentsN(dTrainN,colnames(dTrainN),'y')
print(treatmentsN)

dTrainNTreated <- prepare(treatmentsN,dTrainN,
                          pruneSig=c(),scale=TRUE)
head(dTrainNTreated)

varsN <- setdiff(colnames(dTrainNTreated),'y')
# all input variables should be mean 0
sapply(dTrainNTreated[,varsN,drop=FALSE],mean) 
# all slopes should be 1
sapply(varsN,function(c) { lm(paste('y',c,sep='~'),
   data=dTrainNTreated)$coefficients[[2]]}) 
dTestNTreated <- prepare(treatmentsN,dTestN,
                         pruneSig=c(),scale=TRUE)
head(dTestNTreated)
```